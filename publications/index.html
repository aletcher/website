<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Alistair Letcher | publications</title>
  <meta name="description" content="Alistair Letcher - Homepage
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
  <meta name="google-site-verification" content="Y_iFkfKA5SCNSB6loTvh2deiyEWoL8iMxW6XKkNuLlg" />
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Alistair</strong> Letcher
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="/blog/">blog</a> -->

        <!-- Pages -->
        
          
        
          
            <a class="page-link" href="/code/">code</a>
          
        
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <!--<a class="page-link" href="/assets/cv.pdf">vitae</a>-->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">Publications in reversed chronological order.</h5>
  </header>

  <article class="post-content publications clearfix">
    <h2 class="publications">papers</h2>

<h3 class="year">2021</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="https://iclr.cc" target="_blank">ICLR</a>]</abbr>
  


<div id="global">
  
    <span class="title">On the Impossibility of Global Convergence in Multi-Loss Optimization</span>
    <span class="author">
      
        
          
            <em>A. Letcher</em>
          
        
      
    </span>

    <span class="periodical">
    
      <em>International Conference on Learning Representations,</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
    [<a href="http://arxiv.org/abs/2005.12649" target="_blank">arXiv</a>]
  
  
    [<a href="https://openreview.net/pdf?id=NQbnPjPYaG6" target="_blank">source</a>]
  
  
  
  
  
  
    [<a href="https://github.com/aletcher/impossibility-global-convergence" target="_blank">code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Under mild regularity conditions, gradient-based methods converge globally to a critical point in the single-loss setting. This is known to break down for vanilla gradient descent when moving to multi-loss optimization, but can we hope to build some algorithm with global guarantees? We negatively resolve this open problem by proving that any reasonable algorithm will exhibit limit cycles or diverge to infinite losses in some differentiable game, even in two-player games with zero-sum interactions. A reasonable algorithm is simply one which avoids strict maxima, an exceedingly weak assumption since converging to maxima would be the opposite of minimization. This impossibility theorem holds even if we impose existence of a strict minimum and no other critical points. The proof is constructive, enabling us to display explicit limit cycles for existing gradient-based methods. Nonetheless, it remains an open question whether cycles arise in high-dimensional games of interest to ML practitioners, such as GANs or multi-agent RL.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2020</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="https://nips.cc/" target="_blank">NIPS</a>]</abbr>
  


<div id="ridge">
  
    <span class="title">Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the Hessian</span>
    <span class="author">
      
        
          
            
              
                
                  J. Parker-Holder,
                
              
            
          
        
      
        
          
            
              
                
                  L. Metz,
                
              
            
          
        
      
        
          
            
              
                
                  C. Resnick,
                
              
            
          
        
      
        
          
            
              
                
                  H. Hu,
                
              
            
          
        
      
        
          
            
              
                
                  A. Lerer,
                
              
            
          
        
      
        
          
            
              <em>A. Letcher</em>,
            
          
        
      
        
          
            
              
                
                  A. Peysakhovich,
                
              
            
          
        
      
        
          
            
              
                
                  A. Pacchiano,
                
              
            
          
        
      
        
          
            
              
                and J. Foerster
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Advances in Neural Information Processing Systems,</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
    [<a href="http://arxiv.org/abs/2011.06505" target="_blank">arXiv</a>]
  
  
    [<a href="https://papers.nips.cc/paper/2020/hash/08425b881bcde94a383cd258cea331be-Abstract.html" target="_blank">source</a>]
  
  
  
  
  
  
  
    [<a href="https://bair.berkeley.edu/blog/2020/11/13/ridge-rider/" target="_blank">blog post</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Over the last decade, a single algorithm has changed many facets of our lives - Stochastic Gradient Descent (SGD). In the era of ever decreasing loss functions, SGD and its various offspring have become the go-to optimization tool in machine learning and are a key component of the success of deep neural networks (DNNs). While SGD is guaranteed to converge to a local optimum (under loose assumptions), in some cases it may matter which local optimum is found, and this is often context-dependent. Examples frequently arise in machine learning, from shape-versus-texture-features to ensemble methods and zero-shot coordination. In these settings, there are desired solutions which SGD on ’standard’ loss functions will not find, since it instead converges to the ’easy’ solutions. In this paper, we present a different approach. Rather than following the gradient, which corresponds to a locally greedy direction, we instead follow the eigenvectors of the Hessian, which we call "ridges". By iteratively following and branching amongst the ridges, we effectively span the loss surface to find qualitatively different solutions. We show both theoretically and experimentally that our method, called Ridge Rider (RR), offers a promising direction for a variety of challenging problems.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="http://www.jmlr.org" target="_blank">JMLR</a>]</abbr>
  


<div id="game">
  
    <span class="title">Differentiable Game Mechanics</span>
    <span class="author">
      
        
          
            
              <em>A. Letcher</em>,
            
          
        
      
        
          
            
              
                
                  D. Balduzzi,
                
              
            
          
        
      
        
          
            
              
                
                  S. Racanière,
                
              
            
          
        
      
        
          
            
              
                
                  J. Martens,
                
              
            
          
        
      
        
          
            
              
                
                  J. Foerster,
                
              
            
          
        
      
        
          
            
              
                
                  K. Tuyls,
                
              
            
          
        
      
        
          
            
              
                and T. Graepel
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Machine Learning Research,</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
    [<a href="http://arxiv.org/abs/1905.04926" target="_blank">arXiv</a>]
  
  
    [<a href="http://www.jmlr.org/papers/v20/19-008.html" target="_blank">source</a>]
  
  
  
  
  
  
    [<a href="https://github.com/deepmind/symplectic-gradient-adjustment" target="_blank">code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Deep learning is built on the foundational guarantee that gradient descent on an objective function converges to local minima. Unfortunately, this guarantee fails in settings, such as generative adversarial nets, that exhibit multiple interacting losses. The behavior of gradient-based methods in games is not well understood – and is becoming increasingly important as adversarial and multi-objective architectures proliferate. In this paper, we develop new tools to understand and control the dynamics in n-player differentiable games. The key result is to decompose the game Jacobian into two components. The first, symmetric component, is related to potential games, which reduce to gradient descent on an implicit function. The second, antisymmetric component, relates to Hamiltonian games, a new class of games that obey a conservation law akin to conservation laws in classical mechanical systems. The decomposition motivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding stable fixed points in differentiable games. Basic experiments show SGA is competitive with recently proposed algorithms for finding stable fixed points in GANs – while at the same time being applicable to, and having guarantees in, much more general cases.</p>
  </span>
  
</div>
</li>
<li>
  
    <abbr>[<a href="https://iclr.cc" target="_blank">ICLR</a>]</abbr>
  


<div id="sos">
  
    <span class="title">Stable Opponent Shaping in Differentiable Games</span>
    <span class="author">
      
        
          
            
              <em>A. Letcher</em>,
            
          
        
      
        
          
            
              
                
                  J. Foerster,
                
              
            
          
        
      
        
          
            
              
                
                  D. Balduzzi,
                
              
            
          
        
      
        
          
            
              
                
                  T. Rocktäschel,
                
              
            
          
        
      
        
          
            
              
                and S. Whiteson
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>International Conference on Learning Representations,</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
    [<a href="http://arxiv.org/abs/1811.08469" target="_blank">arXiv</a>]
  
  
    [<a href="https://openreview.net/forum?id=SyGjjsC5tQ" target="_blank">source</a>]
  
  
  
  
  
  
    [<a href="https://github.com/aletcher/stable-opponent-shaping" target="_blank">code</a>]
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>A growing number of learning methods are actually games which optimise multiple, interdependent objectives in parallel – from GANs and intrinsic curiosity to multi-agent RL. Opponent shaping is a powerful approach to improve learning dynamics in such games, accounting for the fact that the ’environment’ includes agents adapting to one another’s updates. Learning with Opponent-Learning Awareness (LOLA) is a recent algorithm which exploits this dynamic response and encourages cooperation in settings like the Iterated Prisoner’s Dilemma. Although experimentally successful, we show that LOLA can exhibit ’arrogant’ behaviour directly at odds with convergence. In fact, remarkably few algorithms have theoretical guarantees applying across all differentiable games. In this paper we present Stable Opponent Shaping (SOS), a new method that interpolates between LOLA and a stable variant named LookAhead. We prove that LookAhead locally converges and avoids strict saddles in all differentiable games, the strongest results in the field so far. SOS inherits these desirable guarantees, while also shaping the learning of opponents and consistently either matching or outperforming LOLA experimentally.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>
  
    <abbr>[<a href="https://2018.ieeeicassp.org" target="_blank">ICASSP</a>]</abbr>
  


<div id="bodyworn">
  
    <span class="title">Automatic Conflict Detection in Police Body-Worn Audio</span>
    <span class="author">
      
        
          
            
              <em>A. Letcher</em>,
            
          
        
      
        
          
            
              
                
                  J. Trišović,
                
              
            
          
        
      
        
          
            
              
                
                  C. Cademartori,
                
              
            
          
        
      
        
          
            
              
                
                  X. Chen,
                
              
            
          
        
      
        
          
            
              
                and J. Xu
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IEEE International Conference on Acoustics, Speech and Signal Processing,</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
    [<a href="http://arxiv.org/abs/1711.05355" target="_blank">arXiv</a>]
  
  
    [<a href="https://ieeexplore.ieee.org/document/8461425" target="_blank">source</a>]
  
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Automatic conflict detection has grown in relevance with the advent of body-worn technology, but existing metrics such as turn-taking and overlap are poor indicators of conflict in police-public interactions. Moreover, standard techniques to compute them fall short when applied to such diversified and noisy contexts. We develop a pipeline catered to this task combining adaptive noise removal, non-speech filtering and new measures of conflict based on the repetition and intensity of phrases in speech. We demonstrate the effectiveness of our approach on body-worn audio data collected by the Los Angeles Police Department.</p>
  </span>
  
</div>
</li></ol>

<h2 class="publications">theses</h2>
<ol class="bibliography"><li>
  
    <abbr>[MSc]</abbr>
  


<div id="msc">
  
    Stability and Exploitation in Differentiable Games, 2018
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/msc_thesis.pdf" target="_blank">pdf</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>While machine learning has traditionally focused on optimising single loss functions, a growing number of algorithms deal with multiple interacting goals, from GANs to multi-agent RL. Naively transposing gradient descent has been shown to fail, while state-of-the-art proposals are tailored to specific applications (e.g. two-player zero-sum games) or lack strong theoretical guarantees. We provide a unified approach to this problem and prove local convergence of Consensus Optimisation, Symplectic Gradient Adjustment and lookahead in all differentiable games. Learning with Opponent-Learning Awareness (LOLA) takes a different approach by shaping and exploiting opponent learning, reaching better equilibria and outperforming previous methods. On the flip side, we construct the first example where this backlashes in self-play, producing arrogant behaviour and poor losses. We address and solve this catch-22 with a new algorithm named Stable Opponent Shaping (SOS), inheriting strong convergence guarantees from lookahead and shaping capacity from LOLA. We obtain convergence of LOLA to equilibria in two-player zero-sum and n-player cooperative games as a corollary.</p>
  </span>
  
</div>
</li>
<li>
  
    <abbr>[BSc]</abbr>
  


<div id="bsc">
  
    Algebraic Features of Multiple Zeta Values, 2017
  

  <span class="links">
  
    [<a class="abstract">abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bsc_thesis.pdf" target="_blank">pdf</a>]
  
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This report aims to present multiple zeta values, a topic which has witnessed a rich mathematical revival and profound breakthroughs in recent years, yet remains cloaked with long-standing conjectures. It is aimed at the undergraduate/first-year postgraduate reader, but we hope that it will be relevant to anyone with curiosity for the subject. The first three chapters introduce the algebraic structure of multiple zeta values in a detailed, rigorous and approachable way. Chapter 4 investigates interpolation (as recently introduced by Yamamoto) and presents a few independent results on the topic. The final chapter gives a glimpse of a more sophisticated approach involving the theory of motives, which has borne powerful results in recent years.</p>
  </span>
  
</div>
</li></ol>

  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2021 Alistair Letcher.
    <a> Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. </a>

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
